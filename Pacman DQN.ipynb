{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gym's Pacman "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Replay Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store our agents memory to reuse this data later for training, sampling randomly for better results with our Neural Network\n",
    "\n",
    "- So let's create a ```class``` named ```Transitions``` that will represent a transition in our environment. It stores our ```(\"state\", \"action\")``` and ```(\"next_state\", \"reward\")```. \n",
    "- And a ```class``` ```ReplayMemory``` with limited size that will hold transitions during our training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\"Transition\", \n",
    "                         (\"state\", \"action\", \"next_state\", \"reward\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, max_size):\n",
    "        \"\"\"\n",
    "        Creates the ReplayMemory object with the maximum size of transitions\n",
    "        \"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"\n",
    "        Saves a transition during training\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.max_size:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Takes a random sample of our training memory\n",
    "        \"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Defines the len() of the ReplayMemory\n",
    "        \"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create a **Deep Q Network** with a convolutional network that will get as ```input``` the state of the environment and will return as ```output``` the expected value for every possible action in that same state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConvNet output size:\n",
    "\n",
    "- W: input volume\n",
    "- K: kernel size\n",
    "- P: padding\n",
    "- D: dilation\n",
    "- S: stride\n",
    "\n",
    "$$\n",
    "outSize = \\frac{W +2P - D\\cdot (K-1)-1}{S}+1\n",
    "$$\n",
    "\n",
    "But in this case we'll be use only Dilation=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, h, w, outputs):\n",
    "        \"\"\"\n",
    "        Creates the ConvNet \n",
    "        \n",
    "        h: int\n",
    "        The screen height\n",
    "        \n",
    "        w: int\n",
    "        The screen width\n",
    "        \n",
    "        outputs: int\n",
    "        The number of actions for the agent\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Calculate the output size of conv to be the input of linear\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass a batch through the ConvNet\n",
    "        \"\"\"\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application, our input (our state) will be the images of Pacman, then we need to process these to use in out network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "def get_screen(env):\n",
    "    screen = env.render(mode=\"rgb_array\").transpose((2, 0, 1))  # HxWxC to CxHxW\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MsPacman-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen(env).cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "MAX_MEMORY = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DQN's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_screen = get_screen(env)\n",
    "_, in_channels, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(in_channels, screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(in_channels, screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(MAX_MEMORY)\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #66 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-6004a8b8daee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mepisode_durations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-35218fd9ea75>\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# detailed explanation). This converts batch-array of Transitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# to Transition of batch-arrays.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Compute a mask of non-final states and concatenate the batch elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #66 must support iteration"
     ]
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen(env)\n",
    "    current_screen = get_screen(env)\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen(env)\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.48326588  0.32935736  0.09632282]\n",
      " [ 0.23085226  0.09634725 -1.15553888]\n",
      " [-0.06260528  0.07440611 -1.12165264]]\n",
      "[[-0.02935934]\n",
      " [-0.46074976]\n",
      " [-2.27293108]]\n",
      "[[-0.04354771 -0.00966971 -0.00282797]\n",
      " [-0.10636512 -0.04439197  0.53241426]\n",
      " [ 0.14229748 -0.16911997  2.54943914]] (3, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(3, 3)\n",
    "b = np.random.randn(3, 1)\n",
    "c = a*b\n",
    "print(a)\n",
    "print(b)\n",
    "print(c, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonAI",
   "language": "python",
   "name": "pythonai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
